import abc
import re # Import regex for parsing LLM output
from typing import List, Dict, Any, Optional
from src.task_management.task import Task
from src.llm_integration.llm_interface import LLMInterface # Import LLMInterface
from src.llm_integration.google_gemini_connector import GoogleGeminiConnector # Import for example usage

class Planner(abc.ABC):
    """
    Abstract base class for a planner.
    Planners are responsible for generating sequences of tasks or actions
    to achieve a specific goal.
    """

    @abc.abstractmethod
    def generate_plan(self, goal_description: str, initial_context: Optional[Dict[str, Any]] = None) -> List[Task]:
        """
        Generates a plan (a list of tasks) to achieve a given goal.

        Args:
            goal_description: A description of the goal to achieve.
            initial_context: Optional initial context or information for planning.

        Returns:
            A list of Task objects representing the plan.
        """
        pass

    @abc.abstractmethod
    def adjust_plan(self, current_plan: List[Task], feedback: Dict[str, Any], context: Optional[Dict[str, Any]] = None) -> List[Task]:
        """
        Adjusts an existing plan based on feedback and current context.

        Args:
            current_plan: The current list of Task objects representing the plan.
            feedback: Feedback received (e.g., from evaluation, agent communication).
            context: Optional current context or information for adjustment.

        Returns:
            An updated list of Task objects representing the adjusted plan.
        """
        pass

# A simple placeholder planner implementation
class BasicPlanner(Planner):
    """
    A basic concrete implementation of the Planner class that uses an LLM
    to generate plans.
    """

    def __init__(self, llm_connector: LLMInterface):
        """
        Initializes the BasicPlanner with an LLM connector.

        Args:
            llm_connector: An instance of a class implementing LLMInterface.
        """
        self._llm = llm_connector
        print(f"BasicPlanner initialized with LLM: {self._llm.get_model_name()}")

    def generate_plan(self, goal_description: str, initial_context: Optional[Dict[str, Any]] = None) -> List[Task]:
        """
        Generates a plan (a list of tasks) to achieve a given goal using the LLM.

        Args:
            goal_description: A description of the goal to achieve.
            initial_context: Optional initial context or information for planning.

        Returns:
            A list of Task objects representing the plan generated by the LLM.
        """
        print(f"BasicPlanner using LLM to generate plan for goal: '{goal_description}'")

        # Craft a prompt for the LLM to generate a plan
        prompt = f"Given the goal: '{goal_description}', break it down into a numbered list of actionable tasks. Focus on clear, distinct steps. If initial context is provided, consider it.\n\n"
        if initial_context:
            prompt += f"Initial Context: {initial_context}\n\n"
        prompt += "Please provide the plan as a numbered list (e.g., 1. Task one\n2. Task two)."

        try:
            # Call the LLM to generate the plan
            llm_response = self._llm.generate_response(prompt)
            print(f"LLM response for plan generation:\n{llm_response}")

            # Parse the LLM's response into a list of tasks
            plan_tasks = self._parse_llm_plan_response(llm_response)

            print(f"BasicPlanner generated {len(plan_tasks)} tasks from LLM response.")
            return plan_tasks

        except Exception as e:
            print(f"Error during LLM-based plan generation: {e}")
            # Fallback or error handling could be added here
            return [] # Return empty list on error

    def _parse_llm_plan_response(self, llm_response: str) -> List[Task]:
        """
        Parses the LLM's response (expected to be a numbered list) into Task objects.
        """
        plan_tasks = []
        # Regex to find numbered list items (e.g., "1. Task description")
        # It handles variations like "1." or "1)" and captures the task description.
        task_pattern = re.compile(r'^\s*\d+[.\)]\s*(.+)$', re.MULTILINE)

        for line in llm_response.splitlines():
            match = task_pattern.match(line)
            if match:
                task_description = match.group(1).strip()
                if task_description:
                    plan_tasks.append(Task(description=task_description))
            else:
                # If a line doesn't match the pattern, it might be part of the previous task description
                # or introductory/concluding text. For this basic parser, we'll ignore non-matching lines
                # after the first task is found, assuming the list format is followed.
                # A more robust parser would handle multi-line task descriptions.
                pass # Ignoring lines that don't match the pattern

        return plan_tasks


    def adjust_plan(self, current_plan: List[Task], feedback: Dict[str, Any], context: Optional[Dict[str, Any]] = None) -> List[Task]:
        """
        Adjusts an existing plan based on feedback and current context using the LLM.
        (Implementation for adjustment is a placeholder for now)
        """
        print(f"BasicPlanner adjusting plan based on feedback: {feedback}")
        # TODO: Implement LLM-based plan adjustment logic here
        # This would involve prompting the LLM with the current plan, feedback, and context
        # and parsing the LLM's suggested adjusted plan.
        print("Plan adjustment not fully implemented in BasicPlanner.")
        return current_plan # Return the current plan as a placeholder

# Example usage (for testing purposes, can be removed later)
if __name__ == "__main__":
    # To run this example, you need to have GOOGLE_API_KEY environment variable set
    # and the google-generativeai library installed (pip install google-generativeai)

    try:
        # Instantiate a Google Gemini connector for the planner
        gemini_connector = GoogleGeminiConnector("gemini-pro") # Use a real Gemini model name

        # Instantiate the BasicPlanner with the LLM connector
        llm_planner = BasicPlanner(llm_connector=gemini_connector)

        goal = "Write a short story about a robot learning to feel."
        print(f"\nGenerating plan for goal: '{goal}'")
        plan = llm_planner.generate_plan(goal)

        print("\nGenerated Plan:")
        if plan:
            for i, task in enumerate(plan):
                print(f"{i+1}. {task.description}")
        else:
            print("No plan generated.")

        # Example of plan adjustment (will use placeholder logic)
        # feedback = {"task_id": "...", "status": "failed", "reason": "..."}
        # adjusted_plan = llm_planner.adjust_plan(plan, feedback)
        # print("\nAdjusted Plan (placeholder):")
        # for task in adjusted_plan:
        #     print(task)

    except ValueError as e:
        print(f"Error: {e}")
        print("Please ensure the necessary API key environment variables are set.")
    except Exception as e:
        print(f"An unexpected error occurred: {e}")